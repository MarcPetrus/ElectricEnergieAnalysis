import streamlit as st
import pandas as pd
import numpy as np
import commun as cn
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import ADASYN
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix 

df = cn.df

st.header("üåÜ "+cn.title+ " - Pr√©vision des blackouts", divider='rainbow')

partie1 = "Pr√©paration"
partie2 = "Comparaison de mod√®les de classification"
partie3 = "Optimisation du mod√®le *Regression Logisique*"

pages=[":beginner: "+partie1, ":books: "+partie2,  "üïπÔ∏è "+partie3]
page=st.sidebar.radio("Aller vers", pages)

@st.cache_data
def get_Df_consos_jour():
    return pd.read_csv(cn.datadir+"puissances_30min_nationale.csv", sep=";",  index_col=0)

df_consos_jour = get_Df_consos_jour()    
df_pic_consos_jour = pd.read_csv(cn.datadir+"max_puissance_jour_nationale.csv", sep=";",  index_col=0)    


if page == pages[0] : 
    st.subheader("Pr√©paration pour comparaison des mod√®les de pr√©dictions.", divider='blue')
    st.markdown('''**Variable cible √† pr√©dire :**  
                Nous avons choisi de r√©pondre √† la question du risque de blackout en prenant comme variable cible le solde √©nerg√©tique.  
                Sous l‚Äôhypoth√®se qu‚Äò un blackout survient lorsque que la production √©nerg√©tique disponible ne parvient pas r√©pondre √† la demande d‚Äô√©nergie, la consommation en l'occurrence, nous avons calcul√© le solde √©nerg√©tique (√† l'√©chelle mensuelle dans cette partie) par l‚Äôop√©ration suivante:''')
    st.code('''Solde = production_brute - consommation   
            avec:  
                - production_brute : production nationale toutes fili√®res √©nerg√©tique sans √©changes avec pays ni perte par pompage (barrages hydro√©lectriques)
                - consommation : toutes r√©gions consid√©r√©es ''')
    st.markdown('''**Interpretation :** Si solde positif, il n'y a pas blackout et le r√©sulat prend 1 comme valeur. Si solde n√©gatif, il y'a blackout et le r√©sultat prend 0 comme valeur. ''')
       
    st.markdown('''**Choix des variables explicatives :**  
                Nous avons eu une premi√®re approche qui a consist√© √† retenir comme variables explicatives celles qui n‚Äôont pas √©t√© consid√©r√©es dans dans le calcul pr√©c√©dent. C'est-√†-dire la  production des diff√©rentes fili√®res √©nerg√©tiques dont les valeurs ont d√©j√† √©t√© consid√©r√©es dans le calcul de la production agr√©g√©e. Les variables restantes consid√©r√©es √† ce niveau comme variables explicatives ont √©t√©:''')
    st.write("- le mois de l‚Äôann√©e (√† travers le calcul de son cosinus)")
    st.write("- la temp√©rature moyenne")
    st.write("- le prix de base moyen de l'√©nergie")
    st.write("- la variable d√©faut d‚Äô√©nergie qui correspond √† fr√©quence de pannes dans les centrales energ√©tiques")
    st.write("- les √©changes d‚Äô√©nergie qui correspond √† l'importation ou √† l‚Äôexportation d‚Äô√©nergie faite par la France")
    
    st.divider()
    
    st.subheader("Pr√©paration pour les optimisations du modele de prediction *Regression Logistique*", divider='red')
    
    st.markdown('''**Sources de donn√©es successivement test√©es :**   
        - toutes les valeurs journali√®res nationale au pas de temps 30 minutes  
        - la demande de puissance maximale nationale de chaque jour ''')            
    
    if st.checkbox("Afficher les donn√©es de puissances nationales au pas de temps 30min "):
        st.dataframe(df_consos_jour, column_config={'annee':st.column_config.NumberColumn(format="%d")})
        
    if st.checkbox("Afficher les donn√©es puissance nationale maximum journali√®re"):
        st.dataframe(df_pic_consos_jour, column_config={'annee':st.column_config.NumberColumn(format="%d")})
    
    st.write('')# saut de ligne
    st.markdown('''**Variable cible √† pr√©dire :**  
                Soit le tableau source de donn√©es nomm√© *df_consos_jour* representant les donn√©es de puissances nationales (aggr√©gation de toutes les r√©gions),  
                la variable cible √† pr√©dire est nomm√©e *manquePuissance* representant un **blackout** a √©t√© d√©finie ainsi :''')
    st.code('''df_consos_jour['deltaPuissance'] = df_consos_jour['production_brute'] - df_consos_jour['consommation']   
            df_consos_jour['manquePuissance'] = df_consos_jour['deltaPuissance'] < 0 ''' , language='python')
    
    st.markdown('''Ainsi le blackout est une valeur 0 ou 1 selon que la diff√©rence entre la puissance √©lectrique demand√©e
                et la production brute sur la demi_heure est positive ou strictmement n√©gative.  
                **:red[La production brute consid√©r√©e pour les pr√©dictions ne prend pas compte les echanges d'energies avec les pays frontaliers, il s'agit de la production brute nationale.]**''')                    
    st.markdown('''**A savoir :** Dans ce mod√®le, on consid√®re qu'il y a un manque de puissance lorsque la production nationale est insuffisante par rapport √† la demande nationale.''')
    
    
if page == pages[1] : 
    st.subheader(partie2, divider='blue')     
    
    df['solde_energie'] = df['production_brute'] - df['consommation']
    #fixation du jeu de donn√©es √† consid√©rer data_definitif
  
    data_definitif = df[['mois_cos', 'ech.physiques', 'solde_energie', 'defaut_energie_moy_jour', 'TMoy', 'prix_base_moyen_ttc']]
    #selection des variables cible et explicatives 

    target = data_definitif.solde_energie
   
    feats = data_definitif.drop('solde_energie', axis = 1)
    # Encodage des classes du solde
    targetx = pd.cut(x = target, bins = [-538450,0,584059], labels = ["blackout", "light"])
    # Cr√©ation de deux nouvelles colonnes targ_blackout et targ_light
    dfxe = data_definitif
    dfxe = dfxe.join(pd.get_dummies(targetx, prefix="targ"))
    
    # Remplacement des valeurs bool√©enes par 1 ou 0
    dfxe.targ_blackout = list(map(int, dfxe.targ_blackout))
    dfxe.targ_light = list(map(int, dfxe.targ_light))
    
    # D√©cision de prendre la variable dfxe.targ_blackout comme variable cible et supprimer dfxe.targ_light
    target = dfxe.targ_blackout
    
    feats = dfxe.drop(['solde_energie', 'targ_light'], axis =1)
    #s√©paration des donn√©es entrainement et test avec 20%
   
    x_train, x_test, y_train, y_test = train_test_split(feats, target, test_size = 0.2)
    #gestion de la valeur manquante de defaut energie

    x_train['defaut_energie_moy_jour'] = x_train['defaut_energie_moy_jour'].fillna(0)

    x_test['defaut_energie_moy_jour'] = x_test['defaut_energie_moy_jour'].fillna(0)
    #gestion des valeurs manquantes
    x_train = x_train.fillna(x_train.median())

    x_test = x_test.fillna(x_test.median())
    #standardisation des donn√©es
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    x_train_sc = scaler.fit_transform(x_train)
    x_test_sc = scaler.transform(x_test)
    #Mod√©lisation Regression Logistique 
   
    from sklearn import tree
    from sklearn.ensemble import RandomForestClassifier
  
    def prediction(classifier):
        if classifier == 'Random Forest':
            clf = RandomForestClassifier()
        elif classifier == 'Decision Tree':
            clf = tree.DecisionTreeClassifier()
        elif classifier == 'Logistic Regression':
            clf = LogisticRegression()
        clf.fit(x_train, y_train)
        return clf

    def scores(clf, choice):
        if choice == 'Accuracy':
            return clf.score(x_test, y_test)
        elif choice == 'Confusion matrix':
            return confusion_matrix(y_test, clf.predict(x_test))
        
    choix = ['Random Forest', 'Decision Tree', 'Logistic Regression']
    option = st.selectbox('Choix du mod√®le', choix)
    st.write('Le mod√®le choisi est :', option)

    clf = prediction(option)
    display = st.radio('Que souhaitez-vous montrer ?', ('Accuracy', 'Confusion matrix'))
    if display == 'Accuracy':
        st.write(scores(clf, display))
    elif display == 'Confusion matrix':
        st.dataframe(scores(clf, display))
    
    st.subheader("Conclusion partielle sur cette premi√®re approche")
    st.write("Les r√©sultats obtenus avec ces trois mod√®les laissent craindre un surapprentissage, m√™me si l‚Äôanalyse pr√©c√©dente des features importance ont montr√© que les variables explicatives utilis√©es semblent √™tre les plus pr√©dictives.")
    st.write("Au niveau des trois mod√®les entrain√©s, les matrix de confusion montrent de l√©g√®res diff√©rences, cela dit avec une bonne pr√©diction des classes. Les scores (accuracy) ont tous pris la valeur de 1. La pr√©cision est parfaite, mais le surapprentissage est √©vident.")

if page == pages[2] : 
    st.subheader('üïπÔ∏è '+partie3, divider='red') 
    st.markdown('''Nous cherchons ici √† optimiser le mod√®le ***Regression Logistique*** predisant les blackout, par :          
> **a.** le choix des donn√©es de consommation
 (cf. *puissance nationale maximum journali√®re* dans la partie *Pr√©paration*)  
> **b.** la recherche des meilleures variables explicatives  
> **c.** le r√©equilibrage des classes de valeurs de la variable cible 'manque_puissance' (optionel)  
> **d**. la recherche des meilleurs param√®tres du mod√®le (Optionel)''')
   
    st.divider()
    
    # initialisation des variables de travail
    major_feats_cols = ['saison', 'mois_sin', 'mois_cos', 'jour_sin', 'jour_cos','thermique', 'nucleaire', 'eolien',\
                        'solaire', 'hydraulique', 'pompage', 'bioenergies', 'ech.physiques','heure', 'TMoy']
    major_feats_cols_cible = major_feats_cols.copy()
    major_feats_cols_cible.append('manquePuissance_codee')  
    df_courant = df_consos_jour
   
    data = df_courant.drop(columns=['deltaPuissance','manquePuissance','manquePuissance_codee'], axis=1)
    target = df_courant['manquePuissance_codee']
    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=789)
    regression_logistique = LogisticRegression(max_iter = 500)
    predictions = None
    probabilitesPredites = None
       
    def updateDf(df_courant = df_consos_jour):   
        '''Met √† jour les variables de travail en fonction des choix de r√©glages de l'utilisateur'''          
        df_courant = df_courant
        data = df_courant.drop(columns=['deltaPuissance','manquePuissance','manquePuissance_codee'], axis=1)
        target = df_courant['manquePuissance_codee']
        X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=789)
                                         
    st.markdown('''##### a. Choix des donn√©es de pics de consommations journali√®res seulement ''')
    st.markdown(''' **Info** : voir la partie Pr√©sentation''')
    if st.checkbox("Utiliser seulement les puissances maximum journali√®re"):
        updateDf( df_pic_consos_jour)
    else:
        updateDf( df_consos_jour)
           
    st.markdown('''##### b. Choix des variables explicatives ''') 
    with st.expander(''' **√âtude des variables explicatives √† utiliser** ''') :
        st.markdown('''V√©rification des corr√©lations entre les features.   
                    **But :** Ne conserver qu'une famille de features libres (le moins corel√©es entre elles) mais les plus corr√©l√©es √† la variable cible *manquePuissance_codee* ''')         
        fig_heat = plt.figure(figsize=(15, 15))
        sns.heatmap(df_courant[major_feats_cols_cible].corr(), annot=True, cmap='RdBu_r', center=0);
        st.pyplot(fig_heat)
        st.markdown('''Nous observons que les variables "echanges physiques" et "thermique" dont une moindre mesure, ont la plus forte corr√©lation statistique avec la variable cible "manque_puissance_codee". ''')
        st.image("Blackout_choix_features_pairplot.png")
        st.markdown('''Sur le graphique pairplot, on remarque que seule la variable 'nucleaire' pr√©sente un intervalle de valeurs pour lesquelles la variable cible est determin√©e : √† partir de 80000, la variable cible reste √† 0.  
                    Nous choisirons en priorit√© les features : **nucleaire et echanges physiques**  
                    Par ailleurs, on observe sur le dernier graph, un d√©s√©quilibre des classes de la variable cible.''')         
    features_selected = st.multiselect(":blue[Selectionnez les variables... ]", major_feats_cols, placeholder="Selectionnez les variables...")
   
    st.markdown('''##### c. R√©equilibrage des classes (optionel)''')
    is_rebalanced_classes = False
    if st.checkbox("R√©equilibrage des classes de la variable cible", disabled=len(features_selected)==0 ):
        is_rebalanced_classes = True  
        X_train_resampled, y_train_resampled = ADASYN().fit_resample(X_train[features_selected], y_train) 
        X_train = X_train_resampled
        y_train = y_train_resampled               
        st.markdown(':green[*Classes de valeurs r√©√©quuilibr√©e !*]')        
    with st.expander(''' **Afficher la r√©partition des classes** de la variable cible 'manque_puissance' ''') :              
        fig_hist, ax = plt.subplots(figsize=(2, 2), layout='constrained')
        ax.hist(y_train)             
        plt.title('R√©partition des valeurs de la variable cible', {'fontsize':'x-small'});
        plt.xlabel('valeur', {'fontsize':'x-small'})
        plt.ylabel("nombre",  {'fontsize':'x-small'});
        plt.yticks(ticks=np.arange(0, 110000, step=10000), fontsize='x-small');
        st.pyplot(fig_hist, use_container_width=False)    
        
    st.markdown('''##### d. Utilisation des meilleurs param√®tres de regression logistique (optionel) ''') 
    is_best_params_search = False
    if st.checkbox("Rechercher puis utiliser les meilleurs param√®tres de regression logistique", disabled=len(features_selected)==0):
        is_best_params_search = True      
        param_grid = [{'C': [0.25, 1, 10], 'solver' : ['newton-cg'], 'penalty' : ['l2', None]},\
            {'C': [0.25, 1, 10 ], 'solver' : ['lbfgs'], 'penalty' : ['l2', None]},\
            {'C': [0.25, 1, 10], 'solver' : ['saga'],  'penalty' : ['elasticnet', 'l1', 'l2', None]}]
        st.write("Param√®tres propos√©s : " )
        st.write(param_grid)
        st.markdown("Documentation : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression")                                    
             
    st.divider()                   
    
    col1, col2 = st.columns([0.7, 0.3])
                
    with col1:
        if st.button(" ‚ñ∂Ô∏è Tester le mod√®le", type="primary", disabled=(len(features_selected)==0 )) :
            # Cas utilisation du GridSearchCV par l'utilisateur
            if is_best_params_search:
                st.markdown('‚è≥  ...plusieurs minutes peuvent √™tre necessaires')
                grid_lr = GridSearchCV(estimator=regression_logistique, param_grid=param_grid)
                grid_lr.fit(X_train[features_selected], y_train)
                predictions = grid_lr.predict(X_test[features_selected])
                
                # Affichage des r√©sultats
                             
                st.markdown('##### :green[**R√©sultats obtenus avec les meilleurs param√®tres :**]')
                st.write("Meilleurs param√®tres trouv√©s:" )
                st.write( grid_lr.best_params_)
                st.write("Score associ√©: (accuracy = nb bonnes pr√©dictions/nb pr√©dictions)", grid_lr.best_score_)  
                st.markdown('Matrice de confusion (vrai positifs, faux positifs,...)')
                st.dataframe(pd.crosstab(y_test, predictions), column_config={'0':st.column_config.NumberColumn(format="%d"), '1':st.column_config.NumberColumn(format="%d")})
                st.divider()
                st.markdown('Rapport des metrics pour chaque classe pr√©dites')
                st.text(classification_report(y_test,predictions))
            # Autres cas
            else:
                regression_logistique.fit(X_train[features_selected], y_train)
                predictions = regression_logistique.predict(X_test[features_selected])
                probabilitesPredites = regression_logistique.predict_proba(X_test[features_selected])
                
                # Affichage des r√©sultats                
                st.markdown('##### :green[**R√©sultats du mod√®le de pr√©diction :**]') 
                st.markdown('Matrice de confusion (vrai positifs, faux positifs,...)')
                st.dataframe(pd.crosstab(y_test, predictions), column_config={'0':st.column_config.NumberColumn(format="%d"), '1':st.column_config.NumberColumn(format="%d")})
                st.divider()
                st.markdown('Rapport des metrics pour chaque classe pr√©dites')
                st.text(classification_report(y_test,predictions))
            
    with col2:    
        if st.button("‚è≠Ô∏è Relancer la page"):
            st.rerun()
            
        if st.button("‚èπÔ∏è Arreter l'execution"):
            st.stop()    
                    